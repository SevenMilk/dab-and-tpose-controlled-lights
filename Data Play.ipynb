{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Data for Visualization\n",
    "\n",
    "Although we've managed to extract a few examples of both dabs and tposes, it's now time to figure out what our data looks like. \n",
    "\n",
    "The easiest way to manipulate and visualize data in Python is via tools like Pandas and Seaborn. \n",
    "\n",
    "But first, we'll need to convert our numpy raw arrays into something that's a bit more readable. So let's do that by converting them into labeled CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dabDataset = np.load('data/dabs.npy')\n",
    "tposeDataset = np.load('data/tposes.npy')\n",
    "otherDataset = np.load('data/other.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8832416e+02, 2.9433704e+02, 7.2265184e-01],\n",
       "       [5.8239331e+02, 3.5126093e+02, 8.0205584e-01],\n",
       "       [5.0984329e+02, 3.4919385e+02, 7.5316119e-01],\n",
       "       [4.1784265e+02, 3.1985785e+02, 8.1164622e-01],\n",
       "       [3.6101605e+02, 2.9243521e+02, 8.0296052e-01],\n",
       "       [6.5091376e+02, 3.6097537e+02, 6.4161348e-01],\n",
       "       [6.3724268e+02, 2.7274924e+02, 7.8188539e-01],\n",
       "       [4.9614203e+02, 2.4154723e+02, 8.3243752e-01],\n",
       "       [5.4315808e+02, 6.4114813e+02, 4.4807938e-01],\n",
       "       [4.8636816e+02, 6.2938318e+02, 3.6906898e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [6.0191382e+02, 6.4702966e+02, 3.8946095e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [5.7648334e+02, 2.7475522e+02, 6.1822432e-01],\n",
       "       [6.0389270e+02, 2.8454663e+02, 4.1854110e-01],\n",
       "       [5.5686536e+02, 2.6891223e+02, 2.7014270e-01],\n",
       "       [6.1959991e+02, 2.9243130e+02, 7.0310913e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding our Labels\n",
    "\n",
    "Our labels come from the [BODY_25 Pose Output format](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/output.md#pose-output-format-body_25) available at the repo. \n",
    "\n",
    "We can tell because when we looked at each of our poses, we saw a `dataset[0].shape` of 25. This matches the number of labels below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Nose\", \"Neck\", \"RShoulder\", \"RElbow\", \"RWrist\", \"LShoulder\", \"LElbow\",\n",
    " \"LWrist\", \"MidHip\", \"RHip\", \"RKnee\", \"RAnkle\", \"LHip\", \"LKnee\", \"LAnkle\",\n",
    " \"REye\", \"LEye\", \"REar\", \"LEar\", \"LBigToe\", \"LSmallToe\", \"LHeel\", \"RBigToe\",\n",
    " \"RSmallToe\", \"RHeel\", \"Background\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of our labels comes as an `X`, `Y`, and `Confidence`. Let's add those labels and flatten this array for our CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "properLabels = []\n",
    "for label in labels:\n",
    "    properLabels.append(label + 'X')\n",
    "    properLabels.append(label + 'Y')\n",
    "    properLabels.append(label + 'Confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/dabs.csv', 'w+') as dabcsv:\n",
    "    dabwriter = csv.writer(dabcsv, delimiter=',')\n",
    "    dabwriter.writerow(properLabels)\n",
    "    for cell in dabDataset:\n",
    "        dabwriter.writerow(cell.flatten())\n",
    "        \n",
    "with open('data/tposes.csv', 'w+') as tposecsv:\n",
    "    tposewriter = csv.writer(tposecsv, delimiter=',')\n",
    "    tposewriter.writerow(properLabels)\n",
    "    for cell in tposeDataset:\n",
    "        tposewriter.writerow(cell.flatten())\n",
    "        \n",
    "with open('data/other.csv', 'w+') as othercsv:\n",
    "    otherwriter = csv.writer(othercsv, delimiter=',')\n",
    "    otherwriter.writerow(properLabels)\n",
    "    for cell in otherDataset:\n",
    "        otherwriter.writerow(cell.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking our Data\n",
    "\n",
    "We can now open up our CSV files and see what they look like. How many samples did we collect? Is it enough? \n",
    "\n",
    "Once we check, we can hop on to the next step, bringing all the data into a single format and file for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Labeled Dataset for Training and Testing\n",
    "\n",
    "Now that we've got our data (mostly) sorted out, we need to convert it into a set. \n",
    "\n",
    "We'll use `0` for `other` poses, `1` for `dabs`, and `2` for `tposes`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "labels = np.zeros(len(otherDataset))\n",
    "labels = np.append(labels, np.full((len(dabDataset)), 1))\n",
    "labels = np.append(labels, np.full((len(tposeDataset)), 2))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# now let's label them for 'one hot'\n",
    "from keras.utils.np_utils import to_categorical\n",
    "one_hot_labels = to_categorical(labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[488.3213     147.51425      0.83340967]\n",
      "  [494.22372    284.5734       0.8012297 ]\n",
      "  [386.4863     270.83716      0.66853976]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[515.7737     112.18818      0.83487195]\n",
      "  [478.48004    274.7029       0.8005627 ]\n",
      "  [368.77948    257.2105       0.6782713 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[547.1316     112.15151      0.79948723]\n",
      "  [464.79065    268.88403      0.73338044]\n",
      "  [360.98135    243.43745      0.62600124]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[509.97504    257.06958      0.892523  ]\n",
      "  [460.9663     351.17117      0.7867987 ]\n",
      "  [372.75305    333.54434      0.6111988 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[554.90063    286.50854      0.88104486]\n",
      "  [496.1236     374.6841       0.7804795 ]\n",
      "  [415.7811     353.13678      0.74092144]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[570.5084     268.88422      0.855286  ]\n",
      "  [509.95016    370.85114      0.7977039 ]\n",
      "  [431.50925    353.08978      0.7552353 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.append(otherDataset, dabDataset, axis=0)\n",
    "dataset = np.append(dataset, tposeDataset, axis=0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 25, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.88321289e+02, 1.47514252e+02, 8.33409667e-01],\n",
       "       [4.94223724e+02, 2.84573395e+02, 8.01229715e-01],\n",
       "       [3.86486298e+02, 2.70837158e+02, 6.68539762e-01],\n",
       "       [3.37498718e+02, 4.31440033e+02, 8.06459844e-01],\n",
       "       [2.76727325e+02, 5.92155334e+02, 6.95721209e-01],\n",
       "       [6.01926575e+02, 2.96297577e+02, 6.77372575e-01],\n",
       "       [6.17621460e+02, 4.47154175e+02, 8.15527081e-01],\n",
       "       [6.33207092e+02, 6.13721497e+02, 7.50288665e-01],\n",
       "       [4.49166534e+02, 6.23515259e+02, 3.33123893e-01],\n",
       "       [3.68768433e+02, 6.15664124e+02, 2.96909660e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.29464417e+02, 6.35266663e+02, 3.00662249e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.72626495e+02, 1.25848732e+02, 7.93599010e-01],\n",
       "       [5.09897217e+02, 1.25915306e+02, 8.75047982e-01],\n",
       "       [4.47158661e+02, 1.31820786e+02, 9.30340886e-01],\n",
       "       [5.51045410e+02, 1.35715973e+02, 8.41542602e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 0. 0. 1. 1. 1. 2. 1. 0. 0. 0. 0. 1. 1. 2. 2. 0. 2. 0. 2. 2. 0. 2.\n",
      " 0. 0. 0. 2. 2. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 2. 0. 0. 2. 2. 0. 2.\n",
      " 0. 1. 1. 2. 0. 0. 0. 2.]\n"
     ]
    }
   ],
   "source": [
    "# now, let's shuffle labels and the array, the same way\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(dataset, labels)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
